import os
import requests
import traceback
from datetime import datetime
from database import log_error

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"
# –ú–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –±–µ—Å–ø–ª–∞—Ç–Ω—É—é –º–æ–¥–µ–ª—å, –Ω–∞–ø—Ä–∏–º–µ—Ä:
# "google/gemini-2.0-flash-exp:free" (–±–æ–ª—å—à–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç)
DEFAULT_MODEL = "stepfun/step-3.5-flash:free"

def call_llm(prompt: str, system_prompt: str = None) -> str:
    if not OPENROUTER_API_KEY:
        msg = "‚ö†Ô∏è –í–Ω–µ—à–Ω–∏–π AI-–ø–æ–º–æ—â–Ω–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ –∑–∞–¥–∞–Ω –∫–ª—é—á API OpenRouter."
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")
        return msg

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://skillforge.local",
        "X-Title": "SkillForge Analyst"
    }

    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º max_tokens, –Ω–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä –º–æ–∂–µ—Ç –µ–≥–æ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å
    payload = {
        "model": DEFAULT_MODEL,
        "messages": messages,
        "temperature": 0.7,
        "max_tokens": 1000  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 1000, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    }

    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] LLM –∑–∞–ø—Ä–æ—Å: {prompt[:200]}...")

    try:
        response = requests.post(OPENROUTER_API_URL, headers=headers, json=payload, timeout=60)

        if response.status_code != 200:
            error_body = response.text
            error_msg = f"‚ùå HTTP {response.status_code}: {error_body[:200]}"
            log_error("LLM_API_HTTP", error_msg, traceback.format_exc())
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {error_msg}")
            return f"–û—à–∏–±–∫–∞ –≤–Ω–µ—à–Ω–µ–≥–æ API: {response.status_code}"

        data = response.json()
        answer = data['choices'][0]['message']['content']
        finish_reason = data['choices'][0].get('finish_reason')

        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏—á–∏–Ω—É –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        if finish_reason == 'length':
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚ö†Ô∏è –û—Ç–≤–µ—Ç –æ–±—Ä–µ–∑–∞–Ω –∏–∑-–∑–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ (finish_reason=length)")
        elif finish_reason == 'stop':
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚úÖ –û—Ç–≤–µ—Ç –∑–∞–≤–µ—Ä—à—ë–Ω —à—Ç–∞—Ç–Ω–æ (finish_reason=stop)")
        else:
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] üîç –û—Ç–≤–µ—Ç –∑–∞–≤–µ—Ä—à—ë–Ω —Å –ø—Ä–∏—á–∏–Ω–æ–π: {finish_reason}")

        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] LLM –æ—Ç–≤–µ—Ç (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤): {answer[:200]}...")
        return answer

    except requests.exceptions.Timeout:
        log_error("LLM_API_TIMEOUT", "Request timeout", traceback.format_exc())
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚ùå –¢–∞–π–º-–∞—É—Ç –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API")
        return "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI-–ø–æ–º–æ—â–Ω–∏–∫–∞."

    except requests.exceptions.ConnectionError:
        log_error("LLM_API_CONNECTION", "Connection error", traceback.format_exc())
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å API")
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ AI-–ø–æ–º–æ—â–Ω–∏–∫—É."

    except Exception as e:
        log_error("LLM_API", str(e), traceback.format_exc())
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ AI-–ø–æ–º–æ—â–Ω–∏–∫—É: {e}"